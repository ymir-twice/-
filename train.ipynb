{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用如下两句可以保持import模块的更新"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random,os\n",
    "import numpy as np\n",
    "def set_random_seed(seed: int) -> None:\n",
    "\trandom.seed(seed)\n",
    "\tos.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\tnp.random.seed(seed)\n",
    "\ttorch.manual_seed(seed)\n",
    "\ttorch.cuda.manual_seed(seed)\n",
    "\ttorch.backends.cudnn.benchmark = False\n",
    "\ttorch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed = 37\n",
    "set_random_seed(seed)\n",
    "class AxialDW(nn.Module):\n",
    "    def __init__(self, dim, mixer_kernel, dilation = 1):\n",
    "        super().__init__()\n",
    "        h, w = mixer_kernel\n",
    "        self.dw_h = nn.Conv2d(dim, dim, kernel_size=(h, 1), padding='same', groups = dim, dilation = dilation)\n",
    "        self.dw_w = nn.Conv2d(dim, dim, kernel_size=(1, w), padding='same', groups = dim, dilation = dilation)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.dw_h(x) + self.dw_w(x)\n",
    "        return x\n",
    "\n",
    "class EncoderBlock(nn.Module):\n",
    "    \"\"\"Encoding then downsampling\"\"\"\n",
    "    def __init__(self, in_c, out_c, mixer_kernel = (7, 7)):\n",
    "        super().__init__()\n",
    "        self.dw = AxialDW(in_c, mixer_kernel = (7, 7))\n",
    "        self.bn = nn.BatchNorm2d(in_c)\n",
    "        self.pw = nn.Conv2d(in_c, out_c, kernel_size=1)\n",
    "        self.down = nn.MaxPool2d((2,2))\n",
    "        self.act = nn.GELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        skip = self.bn(self.dw(x))\n",
    "        x = self.act(self.down(self.pw(skip)))\n",
    "        return x, skip\n",
    "\n",
    "class DecoderBlock(nn.Module):\n",
    "    \"\"\"Upsampling then decoding\"\"\"\n",
    "    def __init__(self, in_c, out_c, mixer_kernel = (7, 7), size = False):\n",
    "        super().__init__()\n",
    "        self.up = nn.Upsample(scale_factor=2)\n",
    "        self.size = size\n",
    "            # self.up = nn.ConvTranspose2d(\n",
    "            #             in_channels=256,\n",
    "            #             out_channels=256,\n",
    "            #             kernel_size=5,  \n",
    "            #             stride=2, \n",
    "            #             padding=1  \n",
    "            #         \n",
    "\n",
    "        self.pw = nn.Conv2d(in_c + out_c, out_c,kernel_size=1)\n",
    "        self.bn = nn.BatchNorm2d(out_c)\n",
    "        self.dw = AxialDW(out_c, mixer_kernel = (7, 7))\n",
    "        self.act = nn.GELU()\n",
    "        self.pw2 = nn.Conv2d(out_c, out_c, kernel_size=1)\n",
    "\n",
    "    def forward(self, x, skip):\n",
    "        if(self.size):\n",
    "            x = F.interpolate(x, size=(25, 25), mode='bilinear', align_corners=True)\n",
    "        else:\n",
    "            x = self.up(x)\n",
    "        x = torch.cat([x, skip], dim=1)\n",
    "        # x = F.interpolate(x, size=(25, 25), mode='bilinear', align_corners=True)\n",
    "        x = self.act(self.pw2(self.dw(self.bn(self.pw(x)))))\n",
    "\n",
    "        return x\n",
    "\n",
    "class BottleNeckBlock(nn.Module):\n",
    "    \"\"\"Axial dilated DW convolution\"\"\"\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "\n",
    "        gc = dim//4\n",
    "        self.pw1 = nn.Conv2d(dim, gc, kernel_size=1)\n",
    "        self.dw1 = AxialDW(gc, mixer_kernel = (3, 3), dilation = 1)\n",
    "        self.dw2 = AxialDW(gc, mixer_kernel = (3, 3), dilation = 2)\n",
    "        self.dw3 = AxialDW(gc, mixer_kernel = (3, 3), dilation = 3)\n",
    "\n",
    "        self.bn = nn.BatchNorm2d(4*gc)\n",
    "        self.pw2 = nn.Conv2d(4*gc, dim, kernel_size=1)\n",
    "        self.act = nn.GELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pw1(x)\n",
    "        x = torch.cat([x, self.dw1(x), self.dw2(x), self.dw3(x)], 1)\n",
    "        x = self.act(self.pw2(self.bn(x)))\n",
    "        return x\n",
    "\n",
    "class self_net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        \"\"\"Encoder\"\"\"\n",
    "        self.conv_in = nn.Conv2d(3, 16, kernel_size=7, padding='same')\n",
    "        self.e1 = EncoderBlock(16, 32)\n",
    "        self.e2 = EncoderBlock(32, 64)\n",
    "        self.e3 = EncoderBlock(64, 128)\n",
    "        self.e4 = EncoderBlock(128, 256)\n",
    "        self.e5 = EncoderBlock(256, 512)\n",
    "\n",
    "        \"\"\"Bottle Neck\"\"\"\n",
    "        self.b5 = BottleNeckBlock(512)\n",
    "\n",
    "        \"\"\"Decoder\"\"\"\n",
    "        self.d5 = DecoderBlock(512, 256)\n",
    "        self.d4 = DecoderBlock(256, 128, size = True)\n",
    "        self.d3 = DecoderBlock(128, 64)\n",
    "        self.d2 = DecoderBlock(64, 32)\n",
    "        self.d1 = DecoderBlock(32, 16)\n",
    "        self.conv_out = nn.Conv2d(16, 4, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Encoder\"\"\"\n",
    "        x = self.conv_in(x)\n",
    "        x, skip1 = self.e1(x)\n",
    "        x, skip2 = self.e2(x)\n",
    "        x, skip3 = self.e3(x)\n",
    "        x, skip4 = self.e4(x)\n",
    "        x, skip5 = self.e5(x)\n",
    "\n",
    "        \"\"\"BottleNeck\"\"\"\n",
    "        x = self.b5(x)          # 512 6 6\n",
    "        \"\"\"Decoder\"\"\"\n",
    "        x = self.d5(x, skip5)   # 256 12 12\n",
    "        x = self.d4(x, skip4)\n",
    "        x = self.d3(x, skip3)\n",
    "        x = self.d2(x, skip2)\n",
    "        x = self.d1(x, skip1)\n",
    "        x = self.conv_out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载数据\n",
    "这里需要先将我们的数据集做成便于torch读取的格式。但是出于方便考虑，就先使用最基本的Dataset重载来实现了\n",
    "\n",
    "#### **后续优化此处也许可以实现FPS性能的提升**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 预处理机制"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据加载器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import *\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "\n",
    "# 定义图像和掩码的预处理\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.Resize((200, 200)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "mask_transform = transforms.Compose([\n",
    "    transforms.Resize((200, 200)),\n",
    "    transforms.Lambda(lambda x: torch.tensor(np.array(x), dtype=torch.long)) \n",
    "])\n",
    "\n",
    "# 创建数据集对象\n",
    "trainset = myDataset(idx_path='stats/train-meta.csv', img_dir='data/images/training/', mask_dir='data/annotations/training/', transform=image_transform, mask_transform=mask_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "trainloader = torch.utils.data.DataLoader(trainset, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练模型\n",
    "### 超参数定义\n",
    "总共有一下几个超参数需要定义: \n",
    " - 优化算法\n",
    " - 学习率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')\n",
    "model = self_net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "betas = (0.9, 0.999)\n",
    "weight_decay = 5e-3\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr, momentum=0.9, nesterov=True, weight_decay=weight_decay)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr, betas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.loss_function.dice_loss import DiceLoss\n",
    "criterion = DiceLoss(weights=[0.68,1.5,0.81,1])#10 20 12 17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练的主循环"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1/1000, total loss 0.00000:   0%|\u001b[38;2;192;255;32m          \u001b[0m| 0/280 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1/1000, total loss 0.00000:   4%|\u001b[38;2;192;255;32m▎         \u001b[0m| 10/280 [00:06<02:42,  1.66it/s, loss=1, lr=0.000333]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m#scheduler = WarmupMultiStepLR(optimizer,milestones=milestones,gamma=0.7,warmup_factor=1.0 / 3,warmup_iters=300)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m epoch_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (inputs, gts) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(pbar):\n\u001b[1;32m     17\u001b[0m     inputs, gts \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), gts\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     18\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py:1182\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1181\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1182\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1185\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/shared-nvme/AI2/dataset.py:31\u001b[0m, in \u001b[0;36mmyDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     28\u001b[0m image \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(img_path)\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     29\u001b[0m mask \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(mask_path)\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 31\u001b[0m image, mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_enhance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n\u001b[1;32m     34\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(image)\n",
      "File \u001b[0;32m~/shared-nvme/AI2/utils/data_augmentation.py:23\u001b[0m, in \u001b[0;36mdata_augmentation\u001b[0;34m(img, label)\u001b[0m\n\u001b[1;32m     21\u001b[0m r_img \u001b[38;5;241m=\u001b[39m add_salt_pepper_noise(r_img, \u001b[38;5;241m0.05\u001b[39m, \u001b[38;5;241m0.5\u001b[39m)\n\u001b[1;32m     22\u001b[0m r_img \u001b[38;5;241m=\u001b[39m median_filter_denoise(r_img, \u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m---> 23\u001b[0m r_img \u001b[38;5;241m=\u001b[39m \u001b[43mCLAHE\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr_img\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r_img, r_label\n",
      "File \u001b[0;32m~/shared-nvme/AI2/utils/data_augmentation.py:86\u001b[0m, in \u001b[0;36mCLAHE\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m     84\u001b[0m r_img_l \u001b[38;5;241m=\u001b[39m clahe\u001b[38;5;241m.\u001b[39mapply(r_img_l)\n\u001b[1;32m     85\u001b[0m r_img[:, :, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m r_img_l\n\u001b[0;32m---> 86\u001b[0m r_img \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_LAB2RGB\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Image\u001b[38;5;241m.\u001b[39mfromarray(r_img)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from utils.lr_scheduler import WarmupMultiStepLR, WarmupCosineLR\n",
    "\n",
    "num_epochs = 1000\n",
    "total_loss = []\n",
    "epoch_loss = 0\n",
    "milestones = [50,100,150,200,250]\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    pbar = tqdm(trainloader, colour='#C0FF20')\n",
    "    total_batchs = len(trainloader)\n",
    "    pbar.set_description(f'{epoch}/{num_epochs}, total loss {epoch_loss:.5f}')\n",
    "    scheduler = WarmupCosineLR(optimizer, T_max=num_epochs + 1, last_epoch=epoch - 2, warmup_factor=1.0 / 3, warmup_iters=200)    # 有热身的cos loss \n",
    "    #scheduler = WarmupMultiStepLR(optimizer,milestones=milestones,gamma=0.7,warmup_factor=1.0 / 3,warmup_iters=300)\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for i, (inputs, gts) in enumerate(pbar):\n",
    "        inputs, gts = inputs.to(device), gts.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, gts)\n",
    "        epoch_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        pbar.set_postfix(loss=loss.item(), lr=optimizer.param_groups[0]['lr'])\n",
    "    \n",
    "    if i == 200 or i == 500 or i == 800:\n",
    "        torch.save(model, \"ULite_tmp.pth\")\n",
    "    scheduler.step()\n",
    "    total_loss.append(epoch_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, f'models/.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 可视化模型结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import utils.vis_result as vst\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(12, 6)) \n",
    "fig.legend(handles=vst.legend_patches, loc='upper right', bbox_to_anchor=(0.65, 1.05), ncol=4)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "vst.plot_result(model, np.random.choice(vst.trainmeta['id']), True, axes[0], True)\n",
    "vst.plot_result(model, np.random.choice(vst.testmeta['id']), False, axes[1], True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
